{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCe8pmy-H4AM",
        "outputId": "e563ebe9-cf17-4f79-99a2-139c2bdce39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print('Completed')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('/content/drive/MyDrive/datasets/train.csv')\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5zsYPDgsJ5lP",
        "outputId": "617d66ea-4683-4b1a-cf6f-40d020e46940"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-446043dc-7786-4a1b-b074-32945eab001d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-446043dc-7786-4a1b-b074-32945eab001d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a5b57bee-c914-434b-b5be-ac8caa774b93\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5b57bee-c914-434b-b5be-ac8caa774b93')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a5b57bee-c914-434b-b5be-ac8caa774b93 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-446043dc-7786-4a1b-b074-32945eab001d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-446043dc-7786-4a1b-b074-32945eab001d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['sentiment'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5cvOnsvKRpv",
        "outputId": "1cd052f9-b773-4c49-a3c1-84efda207755"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neutral', 'negative', 'positive'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.groupby('sentiment').nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "z_f9sLYqKaUO",
        "outputId": "4a99de15-2ccc-408f-9adb-ceef041acaf9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           textID   text  selected_text\n",
              "sentiment                              \n",
              "negative     7781   7781           5861\n",
              "neutral     11118  11117          11111\n",
              "positive     8582   8582           5537"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a45c7949-fa64-4e9c-8476-9bc17395330d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>7781</td>\n",
              "      <td>7781</td>\n",
              "      <td>5861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>11118</td>\n",
              "      <td>11117</td>\n",
              "      <td>11111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>8582</td>\n",
              "      <td>8582</td>\n",
              "      <td>5537</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a45c7949-fa64-4e9c-8476-9bc17395330d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-7c640d3d-f380-4dad-859e-23f9038ecaf1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c640d3d-f380-4dad-859e-23f9038ecaf1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-7c640d3d-f380-4dad-859e-23f9038ecaf1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a45c7949-fa64-4e9c-8476-9bc17395330d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a45c7949-fa64-4e9c-8476-9bc17395330d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['selected_text','sentiment']]\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "WsjPIfuNKgBm",
        "outputId": "55b73107-edbc-4772-9c3f-855d656d48da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         selected_text sentiment\n",
              "0  I`d have responded, if I were going   neutral\n",
              "1                             Sooo SAD  negative\n",
              "2                          bullying me  negative\n",
              "3                       leave me alone  negative\n",
              "4                        Sons of ****,  negative"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-88422faa-2ffc-40fe-97a1-e902f63e2a48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88422faa-2ffc-40fe-97a1-e902f63e2a48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-074e407e-7701-4eeb-9b11-77fd905304be\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-074e407e-7701-4eeb-9b11-77fd905304be')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-074e407e-7701-4eeb-9b11-77fd905304be button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88422faa-2ffc-40fe-97a1-e902f63e2a48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88422faa-2ffc-40fe-97a1-e902f63e2a48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"selected_text\"].fillna(\"No content\", inplace = True)"
      ],
      "metadata": {
        "id": "Inn1DCCNKi0O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def depure_data(data):\n",
        "  url_pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "  data=url_pattern.sub(r'',data)\n",
        "\n",
        "  data = re.sub('\\S*@\\S*\\s?', '', data)\n",
        "\n",
        "  data = re.sub('\\s+', ' ', data)\n",
        "\n",
        "  data = re.sub(\"\\'\", \"\", data)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "Oom7WXADKsv_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "data_to_list=train['selected_text'].values.tolist()\n",
        "for i in range(len(data_to_list)):\n",
        "    temp.append(depure_data(data_to_list[i]))"
      ],
      "metadata": {
        "id": "N0yklxheLHMX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "  for sentence in sentences:\n",
        "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "\n",
        "data_words = list(sent_to_words(temp))\n",
        "\n",
        "print(data_words[:15])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV3_5y6eLSXW",
        "outputId": "7e9c2304-36de-4ad8-a6ce-d9a133a35ba3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['have', 'responded', 'if', 'were', 'going'], ['sooo', 'sad'], ['bullying', 'me'], ['leave', 'me', 'alone'], ['sons', 'of'], ['some', 'shameless', 'plugging', 'for', 'the', 'best', 'rangers', 'forum', 'on', 'earth'], ['fun'], ['soooo', 'high'], ['both', 'of', 'you'], ['wow', 'just', 'became', 'cooler'], ['as', 'much', 'as', 'love', 'to', 'be', 'hopeful', 'reckon', 'the', 'chances', 'are', 'minimal', 'never', 'gonna', 'get', 'my', 'cake', 'and', 'stuff'], ['like'], ['dangerously'], ['lost'], ['test', 'test', 'from', 'the', 'lg', 'env']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detokenize(text):\n",
        "    return TreebankWordDetokenizer().detokenize(text)\n",
        "\n",
        "data = []\n",
        "for i in range(len(data_words)):\n",
        "    data.append(detokenize(data_words[i]))\n",
        "print(data[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bU_N6gWTZsv",
        "outputId": "4efbf3ab-c869-4343-bc2b-857dddeb49a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['have responded if were going', 'sooo sad', 'bullying me', 'leave me alone', 'sons of', 'some shameless plugging for the best rangers forum on earth']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=np.array(data)"
      ],
      "metadata": {
        "id": "EK8yUWgKTt72"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=np.array(train['sentiment'])\n",
        "\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y\n",
        "\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqkoReobTwnO",
        "outputId": "077f235f-e7ee-4c52-993e-b62de6a816d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "print('Completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLEyjob3UCtu",
        "outputId": "219455dd-d285-4f1e-eb11-89dbcb0368e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data)\n",
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al8fHARzUVYF",
        "outputId": "db1d340c-b5c5-4cdf-ebb6-d427536e2e0b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...   68  146   41]\n",
            " [   0    0    0 ...    0  397   65]\n",
            " [   0    0    0 ...    0    0   11]\n",
            " ...\n",
            " [   0    0    0 ...  372   10    3]\n",
            " [   0    0    0 ...   24  542    4]\n",
            " [   0    0    0 ... 2424  199  657]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDngBvDVUZbd",
        "outputId": "531fd5d0-beed-4a7e-9b25-93515cbcda94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20610 6871 20610 6871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single LSTM layer model"
      ],
      "metadata": {
        "id": "0Lbmvx2vUvlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1=Sequential()\n",
        "model1.add(layers.Embedding(max_words,20))\n",
        "model1.add(layers.LSTM(15,dropout=0.5))\n",
        "model1.add(layers.Dense(3,activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yhbjc3uUdN9",
        "outputId": "97e4d175-5b90-4f3f-b1ce-d9fb5f7d5b39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.6423\n",
            "Epoch 1: val_accuracy improved from -inf to 0.73817, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 32s 39ms/step - loss: 0.8194 - accuracy: 0.6423 - val_loss: 0.6675 - val_accuracy: 0.7382\n",
            "Epoch 2/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.7663\n",
            "Epoch 2: val_accuracy improved from 0.73817 to 0.79319, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 9s 14ms/step - loss: 0.5859 - accuracy: 0.7663 - val_loss: 0.5359 - val_accuracy: 0.7932\n",
            "Epoch 3/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8021\n",
            "Epoch 3: val_accuracy improved from 0.79319 to 0.80876, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.5059 - accuracy: 0.8021 - val_loss: 0.5011 - val_accuracy: 0.8088\n",
            "Epoch 4/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.8183\n",
            "Epoch 4: val_accuracy did not improve from 0.80876\n",
            "645/645 [==============================] - 9s 14ms/step - loss: 0.4740 - accuracy: 0.8183 - val_loss: 0.4864 - val_accuracy: 0.8054\n",
            "Epoch 5/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.4506 - accuracy: 0.8273\n",
            "Epoch 5: val_accuracy improved from 0.80876 to 0.81269, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.4506 - accuracy: 0.8273 - val_loss: 0.4760 - val_accuracy: 0.8127\n",
            "Epoch 6/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4416 - accuracy: 0.8316\n",
            "Epoch 6: val_accuracy improved from 0.81269 to 0.81939, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.4416 - accuracy: 0.8316 - val_loss: 0.4637 - val_accuracy: 0.8194\n",
            "Epoch 7/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.8381\n",
            "Epoch 7: val_accuracy improved from 0.81939 to 0.82128, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.4268 - accuracy: 0.8381 - val_loss: 0.4606 - val_accuracy: 0.8213\n",
            "Epoch 8/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8425\n",
            "Epoch 8: val_accuracy improved from 0.82128 to 0.82666, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.4154 - accuracy: 0.8425 - val_loss: 0.4514 - val_accuracy: 0.8267\n",
            "Epoch 9/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4070 - accuracy: 0.8470\n",
            "Epoch 9: val_accuracy improved from 0.82666 to 0.82724, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 9s 14ms/step - loss: 0.4070 - accuracy: 0.8470 - val_loss: 0.4486 - val_accuracy: 0.8272\n",
            "Epoch 10/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.8507\n",
            "Epoch 10: val_accuracy improved from 0.82724 to 0.83045, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.4000 - accuracy: 0.8507 - val_loss: 0.4453 - val_accuracy: 0.8304\n",
            "Epoch 11/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3916 - accuracy: 0.8534\n",
            "Epoch 11: val_accuracy did not improve from 0.83045\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3916 - accuracy: 0.8534 - val_loss: 0.4524 - val_accuracy: 0.8290\n",
            "Epoch 12/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.8555\n",
            "Epoch 12: val_accuracy did not improve from 0.83045\n",
            "645/645 [==============================] - 10s 15ms/step - loss: 0.3869 - accuracy: 0.8555 - val_loss: 0.4390 - val_accuracy: 0.8286\n",
            "Epoch 13/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.8588\n",
            "Epoch 13: val_accuracy did not improve from 0.83045\n",
            "645/645 [==============================] - 6s 10ms/step - loss: 0.3808 - accuracy: 0.8588 - val_loss: 0.4394 - val_accuracy: 0.8291\n",
            "Epoch 14/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3751 - accuracy: 0.8617\n",
            "Epoch 14: val_accuracy did not improve from 0.83045\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3751 - accuracy: 0.8617 - val_loss: 0.4406 - val_accuracy: 0.8299\n",
            "Epoch 15/70\n",
            "641/645 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.8606\n",
            "Epoch 15: val_accuracy did not improve from 0.83045\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3739 - accuracy: 0.8606 - val_loss: 0.4439 - val_accuracy: 0.8275\n",
            "Epoch 16/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.8639\n",
            "Epoch 16: val_accuracy improved from 0.83045 to 0.83248, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 9s 13ms/step - loss: 0.3704 - accuracy: 0.8639 - val_loss: 0.4342 - val_accuracy: 0.8325\n",
            "Epoch 17/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.8639\n",
            "Epoch 17: val_accuracy improved from 0.83248 to 0.83438, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3651 - accuracy: 0.8639 - val_loss: 0.4347 - val_accuracy: 0.8344\n",
            "Epoch 18/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8644\n",
            "Epoch 18: val_accuracy improved from 0.83438 to 0.83452, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3627 - accuracy: 0.8644 - val_loss: 0.4332 - val_accuracy: 0.8345\n",
            "Epoch 19/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.3598 - accuracy: 0.8647\n",
            "Epoch 19: val_accuracy improved from 0.83452 to 0.83714, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.3596 - accuracy: 0.8647 - val_loss: 0.4356 - val_accuracy: 0.8371\n",
            "Epoch 20/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8669\n",
            "Epoch 20: val_accuracy did not improve from 0.83714\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3585 - accuracy: 0.8670 - val_loss: 0.4382 - val_accuracy: 0.8363\n",
            "Epoch 21/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3571 - accuracy: 0.8684\n",
            "Epoch 21: val_accuracy improved from 0.83714 to 0.83743, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 10s 15ms/step - loss: 0.3571 - accuracy: 0.8685 - val_loss: 0.4307 - val_accuracy: 0.8374\n",
            "Epoch 22/70\n",
            "641/645 [============================>.] - ETA: 0s - loss: 0.3493 - accuracy: 0.8694\n",
            "Epoch 22: val_accuracy did not improve from 0.83743\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3490 - accuracy: 0.8696 - val_loss: 0.4452 - val_accuracy: 0.8334\n",
            "Epoch 23/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8718\n",
            "Epoch 23: val_accuracy did not improve from 0.83743\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3505 - accuracy: 0.8718 - val_loss: 0.4279 - val_accuracy: 0.8367\n",
            "Epoch 24/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.8713\n",
            "Epoch 24: val_accuracy did not improve from 0.83743\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3476 - accuracy: 0.8713 - val_loss: 0.4316 - val_accuracy: 0.8374\n",
            "Epoch 25/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3478 - accuracy: 0.8735\n",
            "Epoch 25: val_accuracy improved from 0.83743 to 0.83801, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 6s 10ms/step - loss: 0.3477 - accuracy: 0.8736 - val_loss: 0.4338 - val_accuracy: 0.8380\n",
            "Epoch 26/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.8756\n",
            "Epoch 26: val_accuracy improved from 0.83801 to 0.83845, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3438 - accuracy: 0.8756 - val_loss: 0.4305 - val_accuracy: 0.8385\n",
            "Epoch 27/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8746\n",
            "Epoch 27: val_accuracy did not improve from 0.83845\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3425 - accuracy: 0.8746 - val_loss: 0.4320 - val_accuracy: 0.8373\n",
            "Epoch 28/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8751\n",
            "Epoch 28: val_accuracy did not improve from 0.83845\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3386 - accuracy: 0.8751 - val_loss: 0.4374 - val_accuracy: 0.8382\n",
            "Epoch 29/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.8753\n",
            "Epoch 29: val_accuracy did not improve from 0.83845\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3378 - accuracy: 0.8753 - val_loss: 0.4259 - val_accuracy: 0.8374\n",
            "Epoch 30/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.8751\n",
            "Epoch 30: val_accuracy did not improve from 0.83845\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3365 - accuracy: 0.8752 - val_loss: 0.4299 - val_accuracy: 0.8385\n",
            "Epoch 31/70\n",
            "639/645 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8751\n",
            "Epoch 31: val_accuracy did not improve from 0.83845\n",
            "645/645 [==============================] - 6s 10ms/step - loss: 0.3359 - accuracy: 0.8753 - val_loss: 0.4324 - val_accuracy: 0.8371\n",
            "Epoch 32/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.8768\n",
            "Epoch 32: val_accuracy improved from 0.83845 to 0.83889, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3367 - accuracy: 0.8768 - val_loss: 0.4283 - val_accuracy: 0.8389\n",
            "Epoch 33/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8760\n",
            "Epoch 33: val_accuracy improved from 0.83889 to 0.83976, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3326 - accuracy: 0.8760 - val_loss: 0.4361 - val_accuracy: 0.8398\n",
            "Epoch 34/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8778\n",
            "Epoch 34: val_accuracy did not improve from 0.83976\n",
            "645/645 [==============================] - 9s 14ms/step - loss: 0.3319 - accuracy: 0.8778 - val_loss: 0.4315 - val_accuracy: 0.8396\n",
            "Epoch 35/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.8804\n",
            "Epoch 35: val_accuracy improved from 0.83976 to 0.84093, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3321 - accuracy: 0.8804 - val_loss: 0.4320 - val_accuracy: 0.8409\n",
            "Epoch 36/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.3276 - accuracy: 0.8766\n",
            "Epoch 36: val_accuracy did not improve from 0.84093\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3276 - accuracy: 0.8766 - val_loss: 0.4332 - val_accuracy: 0.8379\n",
            "Epoch 37/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.8790\n",
            "Epoch 37: val_accuracy did not improve from 0.84093\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3264 - accuracy: 0.8790 - val_loss: 0.4337 - val_accuracy: 0.8390\n",
            "Epoch 38/70\n",
            "639/645 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.8802\n",
            "Epoch 38: val_accuracy did not improve from 0.84093\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3274 - accuracy: 0.8802 - val_loss: 0.4270 - val_accuracy: 0.8393\n",
            "Epoch 39/70\n",
            "640/645 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8813\n",
            "Epoch 39: val_accuracy did not improve from 0.84093\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3261 - accuracy: 0.8812 - val_loss: 0.4301 - val_accuracy: 0.8405\n",
            "Epoch 40/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.8823\n",
            "Epoch 40: val_accuracy did not improve from 0.84093\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.3221 - accuracy: 0.8823 - val_loss: 0.4320 - val_accuracy: 0.8393\n",
            "Epoch 41/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.8802\n",
            "Epoch 41: val_accuracy did not improve from 0.84093\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3234 - accuracy: 0.8802 - val_loss: 0.4305 - val_accuracy: 0.8408\n",
            "Epoch 42/70\n",
            "641/645 [============================>.] - ETA: 0s - loss: 0.3205 - accuracy: 0.8825\n",
            "Epoch 42: val_accuracy improved from 0.84093 to 0.84325, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3201 - accuracy: 0.8826 - val_loss: 0.4304 - val_accuracy: 0.8433\n",
            "Epoch 43/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3211 - accuracy: 0.8807\n",
            "Epoch 43: val_accuracy did not improve from 0.84325\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3211 - accuracy: 0.8807 - val_loss: 0.4417 - val_accuracy: 0.8399\n",
            "Epoch 44/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8837\n",
            "Epoch 44: val_accuracy did not improve from 0.84325\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3196 - accuracy: 0.8837 - val_loss: 0.4342 - val_accuracy: 0.8421\n",
            "Epoch 45/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3181 - accuracy: 0.8832\n",
            "Epoch 45: val_accuracy did not improve from 0.84325\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3181 - accuracy: 0.8832 - val_loss: 0.4384 - val_accuracy: 0.8430\n",
            "Epoch 46/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.8843\n",
            "Epoch 46: val_accuracy did not improve from 0.84325\n",
            "645/645 [==============================] - 7s 12ms/step - loss: 0.3159 - accuracy: 0.8843 - val_loss: 0.4304 - val_accuracy: 0.8418\n",
            "Epoch 47/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.8839\n",
            "Epoch 47: val_accuracy improved from 0.84325 to 0.84456, saving model to best_model1.hdf5\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3153 - accuracy: 0.8839 - val_loss: 0.4331 - val_accuracy: 0.8446\n",
            "Epoch 48/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.8850\n",
            "Epoch 48: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3154 - accuracy: 0.8851 - val_loss: 0.4341 - val_accuracy: 0.8434\n",
            "Epoch 49/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.8860\n",
            "Epoch 49: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.3161 - accuracy: 0.8861 - val_loss: 0.4323 - val_accuracy: 0.8431\n",
            "Epoch 50/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.8882\n",
            "Epoch 50: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3106 - accuracy: 0.8882 - val_loss: 0.4391 - val_accuracy: 0.8406\n",
            "Epoch 51/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8859\n",
            "Epoch 51: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.3117 - accuracy: 0.8859 - val_loss: 0.4446 - val_accuracy: 0.8425\n",
            "Epoch 52/70\n",
            "640/645 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.8868\n",
            "Epoch 52: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3118 - accuracy: 0.8868 - val_loss: 0.4416 - val_accuracy: 0.8418\n",
            "Epoch 53/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8865\n",
            "Epoch 53: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3109 - accuracy: 0.8865 - val_loss: 0.4399 - val_accuracy: 0.8396\n",
            "Epoch 54/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.8893\n",
            "Epoch 54: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.3074 - accuracy: 0.8893 - val_loss: 0.4326 - val_accuracy: 0.8433\n",
            "Epoch 55/70\n",
            "640/645 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8882\n",
            "Epoch 55: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.3054 - accuracy: 0.8879 - val_loss: 0.4403 - val_accuracy: 0.8422\n",
            "Epoch 56/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3081 - accuracy: 0.8884\n",
            "Epoch 56: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3081 - accuracy: 0.8885 - val_loss: 0.4375 - val_accuracy: 0.8435\n",
            "Epoch 57/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.8884\n",
            "Epoch 57: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3034 - accuracy: 0.8884 - val_loss: 0.4427 - val_accuracy: 0.8408\n",
            "Epoch 58/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.8885\n",
            "Epoch 58: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3055 - accuracy: 0.8885 - val_loss: 0.4423 - val_accuracy: 0.8430\n",
            "Epoch 59/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.8887\n",
            "Epoch 59: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3031 - accuracy: 0.8887 - val_loss: 0.4468 - val_accuracy: 0.8414\n",
            "Epoch 60/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3052 - accuracy: 0.8895\n",
            "Epoch 60: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.3052 - accuracy: 0.8895 - val_loss: 0.4392 - val_accuracy: 0.8392\n",
            "Epoch 61/70\n",
            "641/645 [============================>.] - ETA: 0s - loss: 0.2995 - accuracy: 0.8920\n",
            "Epoch 61: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 12ms/step - loss: 0.2995 - accuracy: 0.8920 - val_loss: 0.4380 - val_accuracy: 0.8405\n",
            "Epoch 62/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8918\n",
            "Epoch 62: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.3010 - accuracy: 0.8918 - val_loss: 0.4528 - val_accuracy: 0.8409\n",
            "Epoch 63/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8917\n",
            "Epoch 63: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.2993 - accuracy: 0.8917 - val_loss: 0.4459 - val_accuracy: 0.8371\n",
            "Epoch 64/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8954\n",
            "Epoch 64: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.2948 - accuracy: 0.8953 - val_loss: 0.4474 - val_accuracy: 0.8414\n",
            "Epoch 65/70\n",
            "640/645 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8926\n",
            "Epoch 65: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 13ms/step - loss: 0.2959 - accuracy: 0.8929 - val_loss: 0.4462 - val_accuracy: 0.8387\n",
            "Epoch 66/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2993 - accuracy: 0.8924\n",
            "Epoch 66: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.2993 - accuracy: 0.8924 - val_loss: 0.4536 - val_accuracy: 0.8395\n",
            "Epoch 67/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.8920\n",
            "Epoch 67: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.2966 - accuracy: 0.8920 - val_loss: 0.4434 - val_accuracy: 0.8370\n",
            "Epoch 68/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2929 - accuracy: 0.8940\n",
            "Epoch 68: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 10ms/step - loss: 0.2929 - accuracy: 0.8940 - val_loss: 0.4498 - val_accuracy: 0.8409\n",
            "Epoch 69/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.8945\n",
            "Epoch 69: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 8s 12ms/step - loss: 0.2951 - accuracy: 0.8945 - val_loss: 0.4440 - val_accuracy: 0.8406\n",
            "Epoch 70/70\n",
            "641/645 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.8921\n",
            "Epoch 70: val_accuracy did not improve from 0.84456\n",
            "645/645 [==============================] - 7s 11ms/step - loss: 0.2925 - accuracy: 0.8919 - val_loss: 0.4414 - val_accuracy: 0.8402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2=Sequential()\n",
        "model2.add(layers.Embedding(max_words,40,input_length=max_len))\n",
        "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model2.add(layers.Dense(3,activation=\"softmax\"))\n",
        "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcaX_VNHXfIe",
        "outputId": "89ed31b5-7163-4e16-d15c-e06e5216ed5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.7940 - accuracy: 0.6563\n",
            "Epoch 1: val_accuracy improved from -inf to 0.71925, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 32s 44ms/step - loss: 0.7940 - accuracy: 0.6563 - val_loss: 0.6511 - val_accuracy: 0.7193\n",
            "Epoch 2/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.7691\n",
            "Epoch 2: val_accuracy improved from 0.71925 to 0.76539, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.5715 - accuracy: 0.7691 - val_loss: 0.5562 - val_accuracy: 0.7654\n",
            "Epoch 3/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.8063\n",
            "Epoch 3: val_accuracy improved from 0.76539 to 0.81531, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.4990 - accuracy: 0.8063 - val_loss: 0.4902 - val_accuracy: 0.8153\n",
            "Epoch 4/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8231\n",
            "Epoch 4: val_accuracy improved from 0.81531 to 0.81604, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.4648 - accuracy: 0.8231 - val_loss: 0.4764 - val_accuracy: 0.8160\n",
            "Epoch 5/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8306\n",
            "Epoch 5: val_accuracy improved from 0.81604 to 0.81968, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.4456 - accuracy: 0.8306 - val_loss: 0.4673 - val_accuracy: 0.8197\n",
            "Epoch 6/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8372\n",
            "Epoch 6: val_accuracy improved from 0.81968 to 0.82390, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.4300 - accuracy: 0.8372 - val_loss: 0.4554 - val_accuracy: 0.8239\n",
            "Epoch 7/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8429\n",
            "Epoch 7: val_accuracy did not improve from 0.82390\n",
            "645/645 [==============================] - 13s 19ms/step - loss: 0.4169 - accuracy: 0.8429 - val_loss: 0.4543 - val_accuracy: 0.8227\n",
            "Epoch 8/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.8474\n",
            "Epoch 8: val_accuracy improved from 0.82390 to 0.82535, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.4073 - accuracy: 0.8474 - val_loss: 0.4454 - val_accuracy: 0.8254\n",
            "Epoch 9/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8520\n",
            "Epoch 9: val_accuracy improved from 0.82535 to 0.82914, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 11s 17ms/step - loss: 0.3944 - accuracy: 0.8520 - val_loss: 0.4428 - val_accuracy: 0.8291\n",
            "Epoch 10/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8546\n",
            "Epoch 10: val_accuracy improved from 0.82914 to 0.83103, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3882 - accuracy: 0.8546 - val_loss: 0.4416 - val_accuracy: 0.8310\n",
            "Epoch 11/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.8585\n",
            "Epoch 11: val_accuracy did not improve from 0.83103\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3819 - accuracy: 0.8585 - val_loss: 0.4449 - val_accuracy: 0.8307\n",
            "Epoch 12/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8610\n",
            "Epoch 12: val_accuracy improved from 0.83103 to 0.83467, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3746 - accuracy: 0.8610 - val_loss: 0.4343 - val_accuracy: 0.8347\n",
            "Epoch 13/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8631\n",
            "Epoch 13: val_accuracy did not improve from 0.83467\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3720 - accuracy: 0.8631 - val_loss: 0.4399 - val_accuracy: 0.8339\n",
            "Epoch 14/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.8676\n",
            "Epoch 14: val_accuracy did not improve from 0.83467\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3625 - accuracy: 0.8676 - val_loss: 0.4323 - val_accuracy: 0.8332\n",
            "Epoch 15/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.8663\n",
            "Epoch 15: val_accuracy improved from 0.83467 to 0.83816, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 11s 17ms/step - loss: 0.3615 - accuracy: 0.8663 - val_loss: 0.4271 - val_accuracy: 0.8382\n",
            "Epoch 16/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3568 - accuracy: 0.8681\n",
            "Epoch 16: val_accuracy improved from 0.83816 to 0.83860, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 13s 21ms/step - loss: 0.3568 - accuracy: 0.8681 - val_loss: 0.4253 - val_accuracy: 0.8386\n",
            "Epoch 17/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.8704\n",
            "Epoch 17: val_accuracy improved from 0.83860 to 0.84063, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3514 - accuracy: 0.8703 - val_loss: 0.4267 - val_accuracy: 0.8406\n",
            "Epoch 18/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.8749\n",
            "Epoch 18: val_accuracy did not improve from 0.84063\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3449 - accuracy: 0.8749 - val_loss: 0.4283 - val_accuracy: 0.8357\n",
            "Epoch 19/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.8717\n",
            "Epoch 19: val_accuracy did not improve from 0.84063\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3453 - accuracy: 0.8717 - val_loss: 0.4211 - val_accuracy: 0.8396\n",
            "Epoch 20/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8748\n",
            "Epoch 20: val_accuracy did not improve from 0.84063\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3416 - accuracy: 0.8748 - val_loss: 0.4234 - val_accuracy: 0.8389\n",
            "Epoch 21/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.8744\n",
            "Epoch 21: val_accuracy improved from 0.84063 to 0.84078, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3380 - accuracy: 0.8744 - val_loss: 0.4247 - val_accuracy: 0.8408\n",
            "Epoch 22/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.8764\n",
            "Epoch 22: val_accuracy improved from 0.84078 to 0.84151, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3388 - accuracy: 0.8764 - val_loss: 0.4243 - val_accuracy: 0.8415\n",
            "Epoch 23/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.8775\n",
            "Epoch 23: val_accuracy did not improve from 0.84151\n",
            "645/645 [==============================] - 11s 18ms/step - loss: 0.3330 - accuracy: 0.8775 - val_loss: 0.4228 - val_accuracy: 0.8398\n",
            "Epoch 24/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8782\n",
            "Epoch 24: val_accuracy improved from 0.84151 to 0.84340, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3329 - accuracy: 0.8782 - val_loss: 0.4261 - val_accuracy: 0.8434\n",
            "Epoch 25/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8806\n",
            "Epoch 25: val_accuracy did not improve from 0.84340\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.3281 - accuracy: 0.8806 - val_loss: 0.4295 - val_accuracy: 0.8415\n",
            "Epoch 26/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8786\n",
            "Epoch 26: val_accuracy improved from 0.84340 to 0.84398, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 11s 17ms/step - loss: 0.3281 - accuracy: 0.8786 - val_loss: 0.4194 - val_accuracy: 0.8440\n",
            "Epoch 27/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8804\n",
            "Epoch 27: val_accuracy did not improve from 0.84398\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3255 - accuracy: 0.8804 - val_loss: 0.4217 - val_accuracy: 0.8437\n",
            "Epoch 28/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.8815\n",
            "Epoch 28: val_accuracy did not improve from 0.84398\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.3232 - accuracy: 0.8815 - val_loss: 0.4228 - val_accuracy: 0.8427\n",
            "Epoch 29/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8839\n",
            "Epoch 29: val_accuracy did not improve from 0.84398\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3179 - accuracy: 0.8839 - val_loss: 0.4273 - val_accuracy: 0.8434\n",
            "Epoch 30/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.8848\n",
            "Epoch 30: val_accuracy did not improve from 0.84398\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.3172 - accuracy: 0.8848 - val_loss: 0.4245 - val_accuracy: 0.8422\n",
            "Epoch 31/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.8838\n",
            "Epoch 31: val_accuracy did not improve from 0.84398\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3162 - accuracy: 0.8837 - val_loss: 0.4219 - val_accuracy: 0.8425\n",
            "Epoch 32/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.8848\n",
            "Epoch 32: val_accuracy did not improve from 0.84398\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3124 - accuracy: 0.8848 - val_loss: 0.4217 - val_accuracy: 0.8438\n",
            "Epoch 33/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.8876\n",
            "Epoch 33: val_accuracy improved from 0.84398 to 0.84413, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3091 - accuracy: 0.8876 - val_loss: 0.4251 - val_accuracy: 0.8441\n",
            "Epoch 34/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.8852\n",
            "Epoch 34: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.3098 - accuracy: 0.8852 - val_loss: 0.4296 - val_accuracy: 0.8398\n",
            "Epoch 35/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8880\n",
            "Epoch 35: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3074 - accuracy: 0.8880 - val_loss: 0.4263 - val_accuracy: 0.8417\n",
            "Epoch 36/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.8867\n",
            "Epoch 36: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3062 - accuracy: 0.8867 - val_loss: 0.4324 - val_accuracy: 0.8412\n",
            "Epoch 37/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.8902\n",
            "Epoch 37: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3040 - accuracy: 0.8901 - val_loss: 0.4278 - val_accuracy: 0.8387\n",
            "Epoch 38/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.8911\n",
            "Epoch 38: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.3006 - accuracy: 0.8911 - val_loss: 0.4321 - val_accuracy: 0.8418\n",
            "Epoch 39/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8916\n",
            "Epoch 39: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2983 - accuracy: 0.8916 - val_loss: 0.4296 - val_accuracy: 0.8427\n",
            "Epoch 40/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8922\n",
            "Epoch 40: val_accuracy did not improve from 0.84413\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2999 - accuracy: 0.8922 - val_loss: 0.4385 - val_accuracy: 0.8405\n",
            "Epoch 41/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.8923\n",
            "Epoch 41: val_accuracy improved from 0.84413 to 0.84529, saving model to best_model2.hdf5\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2961 - accuracy: 0.8924 - val_loss: 0.4443 - val_accuracy: 0.8453\n",
            "Epoch 42/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.8932\n",
            "Epoch 42: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2958 - accuracy: 0.8932 - val_loss: 0.4343 - val_accuracy: 0.8421\n",
            "Epoch 43/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2963 - accuracy: 0.8917\n",
            "Epoch 43: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2960 - accuracy: 0.8918 - val_loss: 0.4322 - val_accuracy: 0.8427\n",
            "Epoch 44/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.8939\n",
            "Epoch 44: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.2932 - accuracy: 0.8939 - val_loss: 0.4369 - val_accuracy: 0.8428\n",
            "Epoch 45/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8934\n",
            "Epoch 45: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 21ms/step - loss: 0.2909 - accuracy: 0.8934 - val_loss: 0.4349 - val_accuracy: 0.8406\n",
            "Epoch 46/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.8956\n",
            "Epoch 46: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2884 - accuracy: 0.8956 - val_loss: 0.4363 - val_accuracy: 0.8408\n",
            "Epoch 47/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2874 - accuracy: 0.8979\n",
            "Epoch 47: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2874 - accuracy: 0.8979 - val_loss: 0.4416 - val_accuracy: 0.8417\n",
            "Epoch 48/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.2862 - accuracy: 0.8949\n",
            "Epoch 48: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 14s 21ms/step - loss: 0.2865 - accuracy: 0.8950 - val_loss: 0.4408 - val_accuracy: 0.8393\n",
            "Epoch 49/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.8988\n",
            "Epoch 49: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2833 - accuracy: 0.8988 - val_loss: 0.4416 - val_accuracy: 0.8385\n",
            "Epoch 50/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.8975\n",
            "Epoch 50: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2828 - accuracy: 0.8975 - val_loss: 0.4406 - val_accuracy: 0.8411\n",
            "Epoch 51/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.8951\n",
            "Epoch 51: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2856 - accuracy: 0.8951 - val_loss: 0.4476 - val_accuracy: 0.8376\n",
            "Epoch 52/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.8961\n",
            "Epoch 52: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.2821 - accuracy: 0.8961 - val_loss: 0.4448 - val_accuracy: 0.8406\n",
            "Epoch 53/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.8989\n",
            "Epoch 53: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2811 - accuracy: 0.8989 - val_loss: 0.4407 - val_accuracy: 0.8389\n",
            "Epoch 54/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.8993\n",
            "Epoch 54: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.2784 - accuracy: 0.8993 - val_loss: 0.4457 - val_accuracy: 0.8401\n",
            "Epoch 55/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9009\n",
            "Epoch 55: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.2731 - accuracy: 0.9009 - val_loss: 0.4526 - val_accuracy: 0.8403\n",
            "Epoch 56/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2750 - accuracy: 0.9005\n",
            "Epoch 56: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.2750 - accuracy: 0.9005 - val_loss: 0.4550 - val_accuracy: 0.8347\n",
            "Epoch 57/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2725 - accuracy: 0.9028\n",
            "Epoch 57: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.2724 - accuracy: 0.9028 - val_loss: 0.4529 - val_accuracy: 0.8393\n",
            "Epoch 58/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2763 - accuracy: 0.8997\n",
            "Epoch 58: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.2763 - accuracy: 0.8998 - val_loss: 0.4478 - val_accuracy: 0.8431\n",
            "Epoch 59/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.2710 - accuracy: 0.9017\n",
            "Epoch 59: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2709 - accuracy: 0.9017 - val_loss: 0.4560 - val_accuracy: 0.8398\n",
            "Epoch 60/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2744 - accuracy: 0.9013\n",
            "Epoch 60: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 19ms/step - loss: 0.2744 - accuracy: 0.9014 - val_loss: 0.4549 - val_accuracy: 0.8427\n",
            "Epoch 61/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.9019\n",
            "Epoch 61: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 20ms/step - loss: 0.2707 - accuracy: 0.9019 - val_loss: 0.4519 - val_accuracy: 0.8412\n",
            "Epoch 62/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2699 - accuracy: 0.9023\n",
            "Epoch 62: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2699 - accuracy: 0.9022 - val_loss: 0.4486 - val_accuracy: 0.8414\n",
            "Epoch 63/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2701 - accuracy: 0.9040\n",
            "Epoch 63: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2698 - accuracy: 0.9041 - val_loss: 0.4519 - val_accuracy: 0.8412\n",
            "Epoch 64/70\n",
            "643/645 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.9041\n",
            "Epoch 64: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2675 - accuracy: 0.9040 - val_loss: 0.4527 - val_accuracy: 0.8403\n",
            "Epoch 65/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9048\n",
            "Epoch 65: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 13s 19ms/step - loss: 0.2687 - accuracy: 0.9048 - val_loss: 0.4513 - val_accuracy: 0.8373\n",
            "Epoch 66/70\n",
            "645/645 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.9063\n",
            "Epoch 66: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.2657 - accuracy: 0.9063 - val_loss: 0.4639 - val_accuracy: 0.8414\n",
            "Epoch 67/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9054\n",
            "Epoch 67: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 18ms/step - loss: 0.2655 - accuracy: 0.9054 - val_loss: 0.4557 - val_accuracy: 0.8398\n",
            "Epoch 68/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9055\n",
            "Epoch 68: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2651 - accuracy: 0.9055 - val_loss: 0.4526 - val_accuracy: 0.8406\n",
            "Epoch 69/70\n",
            "644/645 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9035\n",
            "Epoch 69: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2655 - accuracy: 0.9035 - val_loss: 0.4601 - val_accuracy: 0.8379\n",
            "Epoch 70/70\n",
            "642/645 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9047\n",
            "Epoch 70: val_accuracy did not improve from 0.84529\n",
            "645/645 [==============================] - 12s 19ms/step - loss: 0.2631 - accuracy: 0.9045 - val_loss: 0.4620 - val_accuracy: 0.8383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model=keras.models.load_model(\"best_model2.hdf5\")\n",
        "\n",
        "test_loss, test_acc = final_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhvwtBZcb-F1",
        "outputId": "2adf7a4b-b61c-40df-b947-0c818c6b4fa8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 - 2s - loss: 0.4443 - accuracy: 0.8453 - 2s/epoch - 9ms/step\n",
            "Model accuracy:  0.845291793346405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = final_model.predict(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcZUsONodHr1",
        "outputId": "381de1a7-4420-4034-d203-6f80a94449b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 2s 6ms/step\n",
            "[[0.00361234 0.00428057 0.9921071 ]\n",
            " [0.00971146 0.9794882  0.01080028]\n",
            " [0.9039309  0.00961103 0.08645809]\n",
            " ...\n",
            " [0.01162008 0.11431974 0.87406015]\n",
            " [0.97575206 0.00737565 0.01687222]\n",
            " [0.81059736 0.17635894 0.01304372]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bZhwvusOdNBd",
        "outputId": "ae6a7407-f495-4ab0-939a-aa3f91d2fa1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-b10c5e1ebd73>:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = ['Neutral','Negative','Positive']"
      ],
      "metadata": {
        "id": "rgvcCcX9dd7d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['this experience has been the worst , want my money back'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "N5N90Xi-dg6t",
        "outputId": "c5422f69-81d6-48be-b947-21ddf1020690"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['i really loved how the technician helped me with the issue that i had'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "nR5Zni8Ndmw1",
        "outputId": "eeefe59f-ba99-46ac-f6c7-3ac6d0c389f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['you are stupid'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zmFzfCgfdq60",
        "outputId": "23c2de90-382a-4a8c-dbe9-f6551f0b32dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['you are stupidly good '])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4s7Ar-d_d4JN",
        "outputId": "f1916753-444c-4428-90db-6ff3d28111e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['you are good stupid'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oJaAL9MLd9u9",
        "outputId": "5c6a2178-0c07-4c30-a004-8f701a088fe7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['Cant you walk straight?'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "veEPQlDveDDd",
        "outputId": "d169b465-d8f9-4e0e-de9b-3991504ebe63"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(['Cant you shoot your brother?'])\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(final_model.predict(test), decimals=0).argmax(axis=1)[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "VbGOCIcDeiO1",
        "outputId": "6465f419-f65e-47f5-bee1-e15f4d5b84c6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}